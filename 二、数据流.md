# 数据流

[toc]

## 概率计数

### Morris 算法

考虑这样一个计数器问题：数据流中只有一种数据，也就是“按动计数器”操作。你的计数器可能随时被查询总共被按了多少次

这个问题十分平凡，一个精确算法如下：

* 维护一个数 $n$，初始时为 0
* 计数器被按动时，令 $n\gets n + 1$
* 查询时，返回 $n$

显然我们需要 $\Theta(\log n)$ 个比特来维护这个数据

但是实际上算法可以使用更少的空间。以下给出一个空间复杂度为 $\order{\log\log n}$ 的算法（Morris）

* 维护一个数 $X$，初始时为 $0$
* 计数器被按动时，以 $2^{-X}$ 的概率令 $X\gets X + 1$
* 查询时，返回 $\tilde n = 2^X - 1$

### 算法分析

>  一个好的算法需要什么呢？需要以很大的概率给出小误差
>
>  只要 $\mathbb E\qty[\tilde n] = n$ 且 ${\rm Var}\qty[\tilde n]$ 不太大，那么我们可以使用切比雪夫不等式来证明算法以很大的概率相对误差比较小。我们首先证明 $\mathbb E\qty[\tilde n] = n$

设 $X_n$ 是按下计数器 $n$ 次后 $X$ 的值

**引理：**$\mathbb E\qty[2^{X_n}] = n + 1$

>  我们尝试找出 $\mathbb E\qty[2^{X_{n + 1}}]$ 与 $\mathbb E\qty[2^{X_n}]$ 之间的关系
>
> 假如 $X_n = j$，那么我们很容易得出 $X_{n + 1}$ 的分布：有 $2^{-j}$ 的概率变成 $j + 1$，有 $1 - 2^{-j}$ 的概率不变。以此可以求出 $X_n = j$ 的时候 $X_{n + 1}$ 的期望。同时 $X_n = j$ 的时候 $X_n$ 的期望就是 $j$，我们在这个基础上进行递推

**证明：**考虑到 $X_0 = 0$ 即 $\mathbb E\qty[2^{X_0}] = 1$，而且
$$
\begin{aligned}
\mathbb E\qty[2^{X_{n + 1}}] &= \sum_{j = 0}^{\infty}\mathbb E\qty[2^{X_{n + 1}} | X_n = j]\mathbb P[X_n = j]\\
&= \sum_{j = 0}^{\infty} \qty(2^{j + 1}\cdot \mathbb P\qty[X_{n + 1} = j + 1 | X_n = j] + 2^j\cdot\mathbb P\qty[X_{n + 1} = j | X_n = j])\mathbb P\qty[X_n = j]\\
&= \sum_{j = 0}^\infty \qty(2^{j + 1}\cdot 2^{-j} + 2^j\cdot (1 - 2^{-j}))\mathbb P\qty[X_n = j]\\
&= \sum_{j = 0}^\infty\qty(2^j + 1)\mathbb P\qty[X_n = j]\\
&= \sum_{j = 0}^\infty 2^j\mathbb P\qty[X_n = j] + \sum_{j = 0}^{\infty}\mathbb P\qty[X_n = j]\\
&= \mathbb E[2^{X_n}] + 1
\end{aligned}
$$
很容易递推得到 $\mathbb E\qty[2^{X_n}] = n + 1$

由以上引理与 $\tilde n = 2^{X_n} - 1$ 可以得知 $\mathbb E\qty[\tilde n] = n$

> 然后我们求出 ${\rm Var}\qty[\tilde n]$，使用与前文类似的方法

观察到 ${\rm Var}\qty[\tilde n] = {\rm Var}\qty[2^{X_n}] = \mathbb E\qty[\qty(2^{X_n})^2] - \mathbb E^2\qty[2^{X_n}] = \mathbb E\qty[2^{2X_n}] - (n + 1)^2$。我们首先求出 $\mathbb E\qty[2^{2X_n}]$

考虑到 $X_0 = 0$ 即 $\mathbb E\qty[2^{2X_0}] = 1$，而且
$$
\begin{aligned}
\mathbb E\qty[2^{2X_{n + 1}}] &= \sum_{j = 0}^{\infty}\mathbb E\qty[2^{2X_{n + 1}} | X_n = j]\mathbb P[X_n = j]\\
&= \sum_{j = 0}^{\infty} \qty(2^{2j + 2}\cdot \mathbb P\qty[X_{n + 1} = j + 1 | X_n = j] + 2^{2j}\cdot\mathbb P\qty[X_{n + 1} = j | X_n = j])\mathbb P\qty[X_n = j]\\
&= \sum_{j = 0}^\infty \qty(2^{2j + 2}\cdot 2^{-j} + 2^{2j}\cdot (1 - 2^{-j}))\mathbb P\qty[X_n = j]\\
&= \sum_{j = 0}^\infty\qty(2^{2j} + 3\cdot 2^j)\mathbb P\qty[X_n = j]\\
&= \sum_{j = 0}^\infty 2^{2j}\mathbb P\qty[X_n = j] + 3\sum_{j = 0}^\infty2^j\mathbb P\qty[X_n = j]\\
&= \mathbb E[2^{2X_n}] + 3\mathbb E\qty[2^{X_n}]\\
&= \mathbb E\qty[2^{2X_n}] + 3(n + 1)
\end{aligned}
$$
易知
$$
\mathbb E\qty[2^{2X_n}] = \mathbb E\qty[2^{2X_0}] + \sum_{i = 0}^{n - 1}3(i + 1) = \frac 32n^2 + \frac 32n + 1
$$
所以
$$
{\rm Var}\qty[\tilde n] = {\rm Var}\qty[2^{X_n}] = \mathbb E\qty[2^{2X_n}] - \mathbb E^2\qty[2^{X_n}] = \frac 32n^2 + \frac 32 n + 1 - (n + 1)^2 = \frac{n^2}2 - \frac n2< \frac {n^2}2 = \order{n^2}
$$
这样切比雪夫不等式就可以估计出相对误差的概率
$$
\mathbb P\qty[\abs{\tilde n - n} > \epsilon n]\leq \frac{{\rm Var}\qty[\tilde n]}{\epsilon^2 n^2} < \frac 1{2\epsilon^2}= \order{\epsilon^{-2}}
$$

> 很遗憾，这个式子没啥用，代入 $\epsilon = 1$，这个式子不能表明本算法有很大的概率误差小于 100%

### Morris+ 算法

为了能给出一个有效的随机计数算法，我们对 Morris 算法稍作修改（记作 Morris+ 算法）

1. 独立运行 $s$ 次 Morris 算法，设这 $s$ 个 Morris 算法的输出分别是 $\tilde n_1, \tilde n_2, \cdots, \tilde n_s$
2. 本算法的输出是这些输出的算术平均 $\tilde n = \frac 1s\sum_{i = 1}^s\tilde n_i$

我们对这个算法进行分析。首先，因为每个子 Morris 算法输出的期望都是 $n$，所以 Morris+ 算法的输出也是 $n$，而方差缩小了 $s^2$ 倍
$$
\mathbb E\qty[\tilde n] = \mathbb E\qty[\frac 1s\sum_{i = 1}^s\tilde n_i] = \frac 1s\sum_{i = 1}^s\mathbb E\qty[\tilde n_i] = \frac 1s ns = n\\
{\rm Var}\qty[\tilde n] = {\rm Var}\qty[\frac 1s\sum_{i = 1}^n\tilde n_i] = \frac 1{s^2}\sum_{i = 1}^n{\rm Var}\qty[\tilde n_i] < \frac 1{s^2}s\frac{n^2}2 < \frac{n^2}{2s}
$$
由切比雪夫不等式
$$
\mathbb P\qty[\abs{\tilde n - n} > \epsilon n] \leq \frac{{\rm Var}\qty[\tilde n]}{\epsilon^2n^2} < \frac{\frac{n^2}{2s}}{\epsilon^2n^2} = \frac 1{2s\epsilon^2}
$$
这样只要 $\frac 1{2s\epsilon^2} \leq \delta$，即 $s\geq\frac 1{2\delta\epsilon^2}$，那么 Morris+ 算法就以超过 $1 - \delta$ 的概率相对误差不超过 $\epsilon$

### Morris++ 算法

以上算法还有改进空间。算法描述如下：

1. 以 $\delta = \frac 13$ 为参数（也就是以 $s = \frac 1{2\cdot\frac 13\epsilon^2}$ 为参数）调用 $t$ 份独立的 Morris+ 算法作为子程序，设 Morris+ 算法的输出分别是 $\tilde n_1, \tilde n_2, \cdots, \tilde n_t$
2. 输出 $\tilde n_1, \tilde n_2, \cdots, \tilde n_t$ 的中位数

> 我们将 $\abs{\tilde n - n}\leq \epsilon n$，也就是相对误差不超过 $\epsilon$ 的概率计数算法输出称为 成功的。我们以 $\delta = \frac 13$ 为参数调用了 Morris+ 算法，也就是以至多 $\frac 13$ 的概率 Morris+ 子程序输出的结果是失败的。Morris+ 算法保证了当 $t$ 非常大的时候，大数定律直观地告诉我们有大约至少 $\frac 23t$ 的 Morris+ 算法子程序是成功的
>
> 而 Morris++ 算法只要有超过 $\frac 12t$ 的 Morris+ 算法子程序是成功就能输出一个成功结果——反着考虑，如果 Morris++ 输出了一个失败的结果，也就是如果 $\abs{\tilde n - n} > \epsilon n$，那么要么 $\tilde n$ 太小了，也就是 $\tilde n - n < -\epsilon n$，要么 $\tilde n$ 太大了，也就是 $\tilde n - n > \epsilon n$。如果 $\tilde n$ 过小，因为 $\tilde n$ 是中位数，所以有 $\frac 12t$ 个 Morris+ 子程序输出比 $\tilde n$ 还小，它们全都是失败的；如果 $\tilde n$ 过大，那么有 $\frac 12t$ 个 Morris+ 子程序输出比 $\tilde n$ 还大，它们也全都是失败的。只要 $\tilde n$ 失败，那么至少有 $\frac 12t$ 个 Morris+ 子程序失败

对于每一个 $i\leq t$，设 $Y_i = \begin{cases}1 & \abs{\tilde n_i - n} \leq\epsilon n\\0 & \abs{\tilde n_i - n} > \epsilon n\end{cases}$

那么由 Morris+ 算法的性质知 $\mathbb P\qty[Y_i = 1]>\frac 23$，这表明
$$
\mathbb E\qty[Y_i] = 1\cdot \mathbb P[Y_i = 1] + 0\cdot\mathbb P[Y_i = 0] = \mathbb P\qty[y_i = 1]>\frac 23
$$

设 $Y = \sum_{i = 1}^tY_i$，则 $Y$ 表示有多少个 Morris+ 子程序成功了，也就是 $Y = \abs{\set{i | \abs{\tilde n_i - n}\leq\epsilon n}}$。那么就有
$$
\mathbb E\qty[Y] = \mathbb E\qty[\sum_{i = 1}^tY_i] = \sum_{i = 1}^t\mathbb E\qty[Y_i] >\frac 23t
$$
所以
$$
\mathbb P\qty[\abs{\tilde n - n}\leq\epsilon n]\leq \mathbb P\qty[Y\leq\frac t2] < \mathbb P\qty[Y -\mathbb E[Y] < -\frac t6]\leq \exp(-2\qty(\frac t6)^2\frac 1t)
$$
最后一个不等式成立是 Chernoff Bound 得出的

这样，只要 $t\geq 18\ln\frac 1\delta$，Morris++ 算法就能成功

### 空间复杂度

当相对误差超过 $\epsilon$ 的概率不足 $\delta$ 的时候，Morris+ 算法调用了 $s = \Theta\qty(\frac 1{\delta\epsilon^2})$ 次 Morris 算法，而 Morris++ 算法调用了 $st = \Theta\qty(\frac 1\epsilon^2\ln\frac 1\delta)$ 次 Morris 算法。我们接下来证明：如果调用了 $s^*$ 次 Morris 算法，那么以至少 $\delta^*$ 的概率，在这 $n$ 次计数过程中每一个数都不超过 $\log\qty(\frac{s^*n}{\delta^*})$

假设某个 Morris 算法在过程中达到了 $X = \log(\frac{s^*n}{\delta^*})$，那么它再增加一次的概率是 $\frac 1{2^X}\leq\frac{\delta^*}{s^*n}$。因为 $X$ 总共只有 $n$ 个机会增加，所以 $X$ 在算法结束的时候有至多 $\frac n{2^X}\leq\frac{\delta^*}{s^*}$ 的概率增加。总共有 $s^*$ 个 Morris 算法，至多有 $s^*$ 个数达到了 $\log\qty(\frac{s^*n}{\delta^*})$ 随时准备突破。所以在算法结束的时候有至多 $\delta^*$ 的概率某个 Morris 算法的 $X$ 超过 $\log\qty(\frac{s^*n}{\delta^*})$ 了。这就表明有至少 $1 - \delta^*$ 的概率所有到达过临界值 $\log\qty(\frac{s^*n}{\delta^*})$ 的 $X$ 都不会再增长了，也就表明有至少 $1 - \delta^*$ 的概率所有 Morris 算法中的 $X$ 都不超过 $\log(\frac{s^*n}{\delta^*})$

这就表明 Morris++ 算法以至少 $1 - \delta^*$ 的概率空间复杂度为
$$
\order{st\log\log(\frac{stn}{\delta^*})} = \order{\qty(\frac 1\epsilon)^2\ln\frac 1\delta\log\log\frac {n\log\frac1\delta}{\epsilon^2\delta^*}}
$$

> 以上分析比较粗糙。一些古老的工作将这个复杂度改进到了 $\order{\log\frac 1\epsilon + \log\log n + \log\frac 1\delta}$，一些较新的工作将这个复杂度改进到了 $\Theta\qty(\log\frac 1\epsilon + \log\log n + \log\log\frac 1\delta)$

## 蓄水池抽样

你面前有一个数据流，数据在不停地流过——你只能看到每个数据一次并且不能将它们全部存储下来。你在任意时刻都可能被要求：“将刚刚你看到的所有数中均匀随机抽取一个给我。”

假设你看到的数依次为 $\set{a_i}_{i = 1, 2, \cdots, \infty}$。类似于 `std::shuffle` 的思想，你可以实现如下地算法：

* 维护变量 $s$，初始时值未定义
* 当看到数据 $a_m$ 的时候，掷骰子，以 $\frac 1m$ 的概率令 $s\gets a_m$，以 $1 - \frac 1m$ 的概率保持 $s$ 不变
* 查询时，直接输出 $s$

这个算法的正确性比较显然。当数据流中流过 $m$ 个数的时候，如果 $s = a_i$，那么第 $i$ 次掷骰子掷得了 $\frac 1i$ 将 $a_i$ 保留下来，而在第 $i + 1, i + 2, \cdots m$ 的时候掷得了 $1 - \frac 1{i + 1}, 1 - \frac 1{i + 2}, \cdots, 1 - \frac 1m$ 而没有将 $a_i$ 扔掉。这些事件都是随机的，所以
$$
\mathbb P\qty[s_m = a_i] = \frac 1i\cdot \frac i{i + 1}\cdot \frac{i + 1}{i + 2}\cdots\frac {m - 1}m = \frac 1m
$$
对于任意的 $i = 1, 2, \cdots, m$ 均成立，也就是说 $a_1, a_2, \cdots, a_m$ 能等概率地在第 $m$ 次出现

分析一下空间复杂度。我们需要存储被抽样的数与当前经过了多少数。假设所有数都不超过 $n$，那么我们的空间复杂度就是 $\order{\log n + \log m}$

## 估计不同元素个数

你需要在任意时刻估计当前数据流中不同元素的个数，并且用尽可能少的事件。设数据流是 $\set{a_i}_{i = 1, 2, \cdots}$ 而且所有数都是整数，你需要在逐一读取这些数据的时候随时准备好回答 $\abs{\set{a_1, a_2, \cdots, a_m}}$

设这个数据流中数的上界是 $n$，你在读取完前 $m$ 个数的时候被要求作答。如果需要求出精确解，有两种方法：

1. 维护一个长度为 $n$ 的数组 $v\in\R^n$ 与计数器 $X$。初始时 $v = \vec 0$。读到一个数 $a_i$ 的时候，如果 $v_{a_i} = 0$，那么就令计数器 $X\gets X + 1$，同时令 $v_{a_i}\gets 1$；如果 $v_{a_i} = 1$，表明 $a_i$ 已经出现过了，就什么都不做。这种方法需要 $n$ 个比特。
2. 直接将读过的数存下来，并维护一个计数器 $X$。当新读到一个数的时候，和之前读过的所有数比较，如果与读过的所有书都不同就令计数器加一。这种方法需要存储 $\order{m\log n}$ 个比特
